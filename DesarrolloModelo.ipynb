{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de redes neuronales: LiftAdvisor\n",
    "\n",
    "Con la intención de cumplir con los objetivos planteados, hemos subdividido nuestro modelo de redes neuronales general en dos partes:\n",
    "1. Modelo de detección de poses: Este modelo funcionará con redes neuronales convolucionales, con el objetivo de captar las imágenes necesarias para detectar la pose de sentadilla, ya sea de frente o de lado, y devolver las coordenadas de las articulaciones de interés.\n",
    "2. Modelo de clasificación y calificación de técnica: Funciona con una red neuronal común, la cual en base a ciertos criterios (que serán especificados posteriormente), recibe las coordenadas halladas en el modelo anterior, y determina la calidad de la sentadilla en un sistema de calificación del 1 al 10.\n",
    "\n",
    "Las unidades de trabajo en la clase de Matemáticas Aplicadas II que se ven involucradas en este proyecto son:\n",
    "1. Unidad 2: Vectores y matrices\n",
    "2. Unidad 3: Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: En esta dinámica, para el planteamiento matemático primero se explicará el modelo de clasificación y calificación de técnica, ya que es mucho más sencillo y sirve de preámbulo para entender matemáticamente el modelo de detección de poses, que implementa funciones un poco más complejas.\n",
    "\n",
    "Subdividiremos este proyecto en las siguientes partes:\n",
    "1. Preprocesamiento y preparación de datos: Divideremos nuestro lote de videos en el grupo de entrenamiento y técnica. La intención es que el modelo de detección de poses devuelva tanto la lista de coordenadas de articulaciones de interés, y se haga un etiquetado automático para poder entrenar y evaluar al segundo modelo.\n",
    "2. Desarrollo del modelo: Se desarrollará el modelo de clasificación y calificación, explicando a profundiad el algoritmo de forward propagation.\n",
    "3. Entrenamiento del modelo: Ya que el éxito del modelo depende de su aprendizaje, plantearemos el algoritmo de backpropagation.\n",
    "4. Evaluación del modelo: En base a nuestro lote de videos y haciendo uso del output del primer modelo, entrenaremos al segundo modelo para que sea capaz de calificar la técnica de una sentadilla de forma correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocesamiento y preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos un modelo implementando las bibliotecas OpenCV y MediaPipe, con el objetivo de detectar la pose de sentadilla (ya sea de frente o de lado) y obtener las coordenadas de las articulaciones de interés. Posteriormente, haremos un proceso de etiquetado automático para cada criterio, y procesaremos nuestro lote de videos de modo que después pueda ser usado para el entrenamiento y evaluación del segundo modelo de redes neuronales.\n",
    "\n",
    "pd: Recordar que la explicación matemática de este primer modelo se realizará posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Función para verificar la pose de sentadilla\n",
    "def es_sentadilla(keypoints):\n",
    "    # Supongamos que la pose de sentadilla se detecta si la rodilla derecha está por debajo de la cadera\n",
    "    cadera = keypoints[24]  # La cadera generalmente corresponde al índice 24\n",
    "    rodilla_derecha = keypoints[26]  # La rodilla derecha generalmente corresponde al índice 26\n",
    "    \n",
    "    if rodilla_derecha[1] > cadera[1]:  # Comparar coordenadas y\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inicializar Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Crear carpeta para guardar los datos si no existe\n",
    "if not os.path.exists('squat_data'):\n",
    "    os.makedirs('squat_data')\n",
    "\n",
    "# Función para procesar el video y detectar la pose de sentadilla\n",
    "def detectar_sentadilla(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convertir imagen de BGR a RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Detectar poses\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convertir imagen de RGB a BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            # Extraer coordenadas de los puntos clave\n",
    "            keypoints = np.array([[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark])\n",
    "\n",
    "            # Guardar los puntos clave en un archivo .npy\n",
    "            np.save(f'squat_data/frame_{frame_count}.npy', keypoints)\n",
    "\n",
    "            # Verificar si la pose es una sentadilla\n",
    "            if es_sentadilla(keypoints):\n",
    "                cv2.putText(image, 'Sentadilla detectada', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Dibujar las poses en la imagen\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Mostrar el video con las poses detectadas\n",
    "        cv2.imshow('Pose Detection', image)\n",
    "        frame_count += 1\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Utilizar la función para procesar el video y detectar la pose de sentadilla\n",
    "video_path = 'ruta/al/video.mp4'\n",
    "detectar_sentadilla(video_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
